# multilingual-generalization-papers
This is a list of papers I'm taking a look at that pertain to improving the performance of multilingual LMs. (Week of 4/11)


## Prompting Multilingual LMs

- Discrete and Soft Prompting for Multilingual Models (https://arxiv.org/pdf/2109.03630.pdf)
- Zero-shot Cross-lingual Transfer of Prompt-based Tuning
with a Unified Multilingual Prompt (https://arxiv.org/pdf/2202.11451.pdf)
- Few-shot Learning with Multilingual Language Models (https://arxiv.org/pdf/2112.10668.pdf)
- Language Models are Few-shot Multilingual Learners (https://arxiv.org/pdf/2109.07684.pdf)


## Extending / Adapting Multilingual LMs

- Extending Multilingual BERT to Low-Resource Languages (https://aclanthology.org/2020.findings-emnlp.240.pdf)
- MAD-X: An Adapter-Based Framework for
Multi-Task Cross-Lingual Transfer (https://aclanthology.org/2020.emnlp-main.617.pdf)
- Continual Learning in Multilingual NMT via Language-Specific
Embeddings (https://aclanthology.org/2021.wmt-1.62.pdf)
- UNKs Everywhere:
Adapting Multilingual Language Models to New Scripts (https://aclanthology.org/2021.emnlp-main.800.pdf)
- AdapterFusion:
Non-Destructive Task Composition for Transfer Learning (https://aclanthology.org/2021.eacl-main.39.pdf)
- When Being Unseen from mBERT is just the Beginning:
Handling New Languages With Multilingual Language Models (https://aclanthology.org/2021.naacl-main.38.pdf)
- Adapting BigScience Multilingual Model to Unseen Languages (https://arxiv.org/pdf/2204.04873.pdf)
